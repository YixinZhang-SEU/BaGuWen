## 自我介绍

各位老师下午好。我叫张易新，来自东南大学计算机科学与工程学院。我硕士期间的研究方向是云计算调度、云边端任务卸载等。研究生期间我撰写了一篇专利，参与了三个企业合作项目，是其中一个项目的主要负责人。专利与我实验室的研究方向一致，名为基于马尔可夫决策过程的工作流任务卸载方法，三个项目分别与基站ip分配、自然语言处理和终端在离线混部调度有关。欢迎各位老师提问。



## 消保领域文本分析与处理系统 | 平安集团合作项目

**使用技术**： Python，LDA 模型，TF/IDF 模型，SVM监督学习算法。

**项目概述**： 根据消保领域文本特点，本项目需实现消保行业的中文文本分词、关键词提取、文本分类等功能。

**主要职责**： 

1. 使用一阶CRF模型结合ADF训练方法，获得消保领域的分词模型，并根据此和自定义词典生成文本标注和字典树， 进行文本分词； 
2. 分别使用 TF/IDF 和 LDA 主题模型计算词语碎片综合权重，再对相邻碎片关键词进行融合，生成关键短语； 
3. 分别根据关键词序列、关键词权重生成向量编码、为向量赋权，生成每一个关键词的集成决策树，以关键词为特征将文本分类。

**项目成果**： 通过公司验收，系统已嵌入到平安集团后台业务中。

> **分词**
>
> 在训练模型部分，我们需要输入若干篇已经分过词的文本作为训练集。训练基于单词的特征和(标签-过渡)特征，使用条件较为简单的**一阶条件随机场用于汉语分词和新单词检测的联合建模**。我们用**ADF算法，即基于特征频率信息的自适应在线梯度下降**对模型进行训练。ADF算法不像随机梯度下降（SGD算法）这样的所有参数都使用单一的学习率，而是**将学习率转换为与参数具有相同维度的向量**。每个参数的学习率会根据参数的频率自动调整。这个使频率更高的特征会更容易被筛选出。训练后，我们得到了一个消保领域的分词模型文件，文件中包含训练得到的词库和对应的分词权重。
>
> 在正式分词部分，我们先**预加载刚刚训练好的模型**，另外还需加载一个**自定义词典**，这个词典主要是基于公司给的关键词集合。因为这些关键词都是一些偏专有的词汇，另外还有一些例如中国银保监会这种固定机构名，我们希望分词的时候不把它们分开。后续我们会持续更新自定义词典的词。首先要构建字典树以便存储所有词。在分词时**先把文本与字典树作匹配**，摘取出所有在用户词典中已经出现的词。接下来对剩余的文本利用CRF模型生成字标注，并把有标注的词与训练得到的词库对比，在词库中就分出来，不在的话看特征概率，高于50%的话就加到词库中并分出，否则先抛弃不分词。
>
> **关键词提取**
>
> 接下来到了关键词提取的部分。首先要**对文本做一个预处理，预处理包含分词、词性标注、去停用词和文本中的杂质**几个部分。接着读取TF-IDF文件和单词话题权重文件，预计算主题突出度。然后再把词语做碎片化细分，开始清洗文本、计算词频，对每个词进行词性标注和语义角色标注，获取候选短语。对候选短语使用**TF-IDF和LDA主题模型**计算候选短语在各个主题中的权重。最后用MMR算法重排结果，减少相似候选词的冗余。
>
> TF-IDF用以评估一字词对于一个[文件集](https://baike.baidu.com/item/文件集/12724334?fromModule=lemma_inlink)或一个语料库中的其中一份文件的重要程度；LDA主题模型根据概率分布为一段文本生成主题。
>
> **文本分类**
>
> 分类器：
> 1）通过尝试不同的算法：SVM、决策树、贝叶斯方法等，择优选取，并结合集成学习综合多个弱分类器的结果，提升算法效果，算法的分类准确率从87.6%提升至96%。（1000篇文章的测试结果）
> 2）综合多个分类器结果，处理空值问题。在多个分类器都没有输出结果时，选择最有可能的权益，优先保证至少输出一种权益分类。
>
> **难点与解决**
>
> 难点：调参
>
> 参数主要是这几个，**一个是ADF学习衰减值，超参数α和β，训练轮数以及迭代次数**。数据集一个是用公司之前提供的两篇分过词的文章，另一个加上了我们自己分的三十篇文章。训练时我们调整了一些参数，对比了f-score，这个**f-score就是训练出的结果与测试集对比的准确率**，发现**学习率rate在0.20或0.25时f-score比较好**。接下来我们就用0.20作为学习衰减值，0.995和0.6分别作为超参数，训练消保领域的约XX篇文本，得到了一个约有XX词的词库。另外我们的自定义词典中有约350词。
>
> 解决：耐心调，切忌浮躁



## 分布式IP地址防碰撞分配算法寻优 | 华为合作项目

**使用技术**： C++， Python， Golang多线程，分布式算法。

项目概述： 某区域内的基站都可以为用户分配IP地址，但当该用户移动到另一基站时，新基站必须为其重新分配不重复的新IP地址，否则就会产生地址碰撞，本项目力图减少整体的碰撞概率。

**主要职责**：

1. 为解决基站节点数量发生变化时的数据迁移问题，提出使用一致性哈希算法替代华为现有算法；
2. 为解决传统一致性哈希算法的数据倾斜问题，提出将单个基站节点转化为多个虚拟节点后再映射到哈希环上；
3. 为解决单个基站节点用户数量突然增多的突发性负载问题，提出分布式染色算法显著提高每个基站节点可分配的IP地址数量。

**项目成果**： 华为使用广州市天河区基站历史数据进行测试，新算法成功将碰撞概率从11%降至1%。

> **一致性哈希**
>
> 1. 将整个哈希值空间（总共65536个ip地址）围成一个虚拟的哈希圆环
> 2. 将基站编号通过哈希函数进行哈希，确定基站在哈希环上的位置。
> 3. 使用哈希算法将ip映射到哈希环上的某一个位置，顺时针找到第一个基站即为此ip所在的基站，需要注意的是单个基站至多连接1200个ip，如果超限了就顺时针次分配到下一个基站。
>
> 一致性哈希解决了单个基站节点数量发生变化后，所有基站都需要重新分配ip的数据迁移问题。
>
> **哈希环的虚拟节点**
>
> 在基站比较少的情况下，容易因为ip分布不均匀而造成数据倾斜问题，也就是大部分ip集中在相邻的某几个基站，这种情况就称为哈希环的倾斜。为了解决这种数据倾斜问题，我们引入了虚拟节点机制，即每一个基站计算多个哈希，每个计算结果位置都为该基站的虚拟节点，一个实际物理基站节点可以对应多个虚拟节点，虚拟节点越多，哈希环上的节点就越多，ip被均匀分布的概率就越大，哈希环倾斜所带来的影响就越小，哈希算法基本不变，只是多了一步虚拟节点到实际节点的映射。
>
> **分布式染色算法**
>
> 1. 节点设置优先级
>
> 优先级按照：本节点所需色块数量，邻居数量，id大小来依次比较
>
> 2. 节点分配颜色
>
> 3. 异常处理
>
> **难点与解决**
>
> 难点：一步步想出优化的方法比较难
>
> 解决：多与小组成员讨论交流，多学习查阅现有论文，多做实验验证新想法的合理性

ip范围：0\~65535；路由器范围：1\~144；每台路由器的邻居数：0\~32；每台路由器最多分配ip数：1200

### 华为最初构想

哈希表长度：len = 现有基站数

`ip_id mod len = base_id`

问题：ip地址是实时动态变化的，也即如果基站数量改变了，那么所有的ip地址可能都要重新分配

### 优化算法1

既然直接取余不行，我们就想到了一致性哈希算法，把现有的基站平均分布到一个具有65536个点位的哈希环上，这样的话每一个基站负责哪些范围的ip就一目了然了，这就解决了基站增加或减少之后，所有ip都要变动的问题。只有部分的ip所在的基站会改变。

问题：哈希环的共性问题，数据倾斜问题。虽然一开始是均匀分布基站的，但有可能某些基站被撤走，极端的情况就是被撤走的基站集中在同一个半圆上，那么顺时针第一个没有被撤走的基站就要承担更多的ip地址，这个基站不一定有这么大的潜在用户，且单个基站最多只能连接1200个终端，其他的基站可能需要更多ip，但根据一致性哈希，这些有需求的基站反而得不到ip地址，这就有严重的数据倾斜问题了。

### 优化算法2

这个优化也是参考现有算法，把这些实体基站分别映射成若干个虚拟基站，在向哈希环添加该基站时也把虚拟基站加进去。

### 优化算法3

新思路：既然要减少碰撞发生的概率，那么只要相邻基站分配不一样的ip就好了，这是一种静态分配的方式。一旦分了这个范围，除非实在不够用了，否则不会变动。

抽象成了染色算法，计算为了让相邻路由器分配不同颜色，最多需要多少个颜色。但因为真正的基站不在同一片区域，所以这是一个分布式的算法。根据贪心思想，我们要尽量从网络拓扑结构中最复杂的一块入手，因为这一块最容易产生ip碰撞。

### 难点

从华为算法出发，从现有的算法跳出来，想到一个全新思路比较难。 包括这个染色算法前期也有不到位的情况，如何优化完善是一个循序渐进的过程。





## 特征多样干扰多源的终端云业务在离线混部集群调度 | 华为合作项目  

终端云场景具有业务特征多样化、资源需求差异大波动大、业务间干扰难以预测等特点。 本项目借助历史数据和终端云业务特征，拟降低在离线混部集群的资源利用率。

### 任务

在线任务：对响应时延要求高，要求尽快响应，但是任务量不大；离线任务：任务量非常大，计算时间长，但是不需要立刻响应。

### 干扰

任务干扰、资源干扰、外部干扰（业务需求的资源类型繁多，如TLB快表、L1/2 缓存、缓存带宽、内存带宽、总线带宽等诸多关键资源仍然缺乏对应的软硬件协同资源隔离机制，尚无法实现应用级隔离。  

### 模块

> 1. 构建多样化业务特征的定量关系模型。分析成功率与资源利用率之间的关系，通过监测到的业务指标来**检测干扰**；

因为干扰的发生不是可以预测或立即观察得到的，我们只能通过其他手段来推测出干扰的产生。根据历史数据和压力测试采样数据拟合出没有干扰时各业务特征之间的关联关系，这样当我们监测业务特征时，发现数据明显偏离应有的范围，那么就可以认为是发生了干扰。

> 2. 基于多源干扰反推学习来预防干扰。为区分显性干扰和非显性干扰，建立干扰关系矩阵来表示业务间发生干扰的概率如何。实际业务场景中，再根据某一干扰发生的概率来反推干扰的性质并加以针对性的预防措施；

建立一个业务间干扰关系的热力图，检测不同任务间互相干扰的概率如何。设定一个阈值$\beta$，大于它即为显性干扰。对于互相存在显性干扰的业务，我们可以控制其不调度在同一个pod，但是对于非显性干扰，我们就无法直接预测并解决。这时就用到第一步得出来的特征间定量关系模型来反推。

> 3. 考虑显性和非显性干扰的在离线业务混部集群调度。根据业务集、资源集、调度目标、约束条件四个要素， 设计实时智能调度算法。

分为事前、事中、事后三个阶段

 (1) 事前规避。尽可能避免将存在显性干扰关系的业务部署在同一计算节点上，这可以通过在调度过程中施加外部约束实现。  

（2）事中检测。在终端云的业务运行过程中检测到非显性干扰时，采用适当的处理策略（如迁移在线任务、驱逐离线任务等），将最近创建的实例（最近创建的实例视为非显性干扰源）转移至其他计算节点。  

（3）事后处理。在业务版本更新后，业务之间的干扰关系可能也会发生变化（显性干扰与非显性干扰间转换）。因此，需要动态检测和调整业务之间的干扰关系，从而为后续的业务运行提供更精准的帮助。



## 专利：一种基于马尔可夫决策过程的工作流任务卸载方法  

本发明公开了一种基于马尔可夫决策过程的工作流任务卸载方法，包括

1. 预处理阶段：对整个云边端系统进行资源监测与记录，定义服务器集合和网络拓扑的邻接矩阵表；

2. 解决方案阶段：对于每一个待卸载的工作流，构造直接前驱表、已卸载任务集、待卸载任务集等，基于工作流构建马尔可夫决策过程模型，根据价值函数选出当前状态下的最佳决策；

3. 更新阶段：根据不同原因产生的状态更新，更新系统各参数。

本发明使用马尔可夫决策过程，在异构云边端场景下解决工作流卸载问题，优化了任务的最快完成时间，在移动物联网领域有广泛的应用价值和使用前景。  



## 反问

### 荣耀

1. IT应用开发岗所在的部门主要业务有哪些？这个岗位和通用软件开发岗位的区别是什么样的？
2. C++还是Java多一些
3. （根据1的问题）我如果想让自己的专业技能更加匹配贵部门，更加推荐去学习哪些知识，或者书籍？



























